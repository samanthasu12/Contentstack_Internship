{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samanthasu12/Contentstack_Internship/blob/main/L%26DDataCalculation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Welcome to my L&D Automation Project!**\n",
        "----\n",
        "Here are the steps in which you need to take to automate the data.\n",
        "1.  Make sure that all the sheets are completely blank except for the column titles.\n",
        "2. Insert the LearnUpon report into the Employee Data sheet. **NOTE:** The report must contain the following columns: First Name,\tLast Name,\temail,\tenabled,\texpires,\tCourse name,\tcourse ref. code,\tenrolled,\tsource,\tdue date,\tstarted,\tLast Accessed,\tLast Accessed Module,\tcompleted,\tPass Mark,\tScore,\tStatus,\tCan re-attempt?,\tPercentage Complete,\tExpiration date,\tGroups,\tStarted, Date/Time,\tLast Accessed Date/Time,\tand Completed Date/Time.\n",
        "3. Insert the UKG report into the People Ops Data sheet.  **NOTE:** The report must contain the following columns: Employee Number,\tEmployee Name, (Last Suffix, First MI),\tEmployee Email,\tEmployment Status Code,\tEmployment Type,\tJob,\tSupervisor Name (First MI Last Suffix),\tOrg Level 1,\tOrg Level 2,\tOrg Level 3,\tOrg Level 4, and\tLocation\n",
        "4. Make sure the sheet names in the google sheet are the following: Course A, Employee Data, and People Ops Data.\n",
        "5. After you've completed your checks, please click Runtime (located at the very top of the colab) and Run All. It will then ask you to connect the google colab to your own google account, and you just need to sign in.\n",
        "6. Please give it around 6 minutes to fully automate. (Might be longer depending on how big the report is)\n"
      ],
      "metadata": {
        "id": "4OTkrlXLMpYY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95uSdcOFCNvE"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from google.auth import default\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from google.colab import drive\n",
        "from google.colab import auth\n",
        "from IPython.display import clear_output\n",
        "creds, _ = default()\n",
        "drive.mount('/content/drive/')\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "drive.mount(\"mnt\")\n",
        "!pip install --upgrade gspread\n",
        "import gspread\n",
        "from datetime import date\n",
        "\n",
        "sheet_id='1zBvZf07H6HrQNsCRNs2-d22T31KnHi65m5iZbzLgxrY'\n",
        "#the sheet_id is the \"key\" to unlocking the spreadsheet that I am importing/exporting onto/from (which in this case is the TA Master Spreadsheet).\n",
        "#The key is found after /d/ and before /edit in https://docs.google.com/spreadsheets/d/1qZh3oDeFjUqQu8RecKGn-Wb9BE3m0iI3OYab1dBg52I/edit#gid=317505658\n",
        "\n",
        "sh = gc.open_by_key(sheet_id)\n",
        "sh.worksheets()\n",
        "\n",
        "!pip install pandasql\n",
        "import sqlite3\n",
        "clear_output()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the code block below to sync up the functions."
      ],
      "metadata": {
        "id": "j7FcHiQR8xPU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ng06uOp3NRU"
      },
      "outputs": [],
      "source": [
        "#functions\n",
        "def WorksheetLoading(Name):\n",
        "  Data_Worksheet=sh.worksheet(Name)\n",
        "  Data_Worksheet=Data_Worksheet.get_all_values()\n",
        "  headers1 = Data_Worksheet.pop(0)\n",
        "  AllEmployeeData=pd.DataFrame(Data_Worksheet, columns=headers1)\n",
        "  return AllEmployeeData\n",
        "\n",
        "def WorksheetNaming(Name):\n",
        "  Sheet_Worksheet=sh.worksheet(\"Course A\")\n",
        "  Sheet_df=pd.DataFrame(Sheet_Worksheet.get_all_records())\n",
        "  return Sheet_df\n",
        "\n",
        "def Update(dataframe,worksheet):\n",
        "  rows_to_update=dataframe[dataframe['Email']==\"*\"]\n",
        "  for row in rows_to_update.itertuples(index=True, name='Pandas'):\n",
        "    dataframe['Employee Name'] = merged_df.sort_values(by='Email')['Employee_Name']\n",
        "    dataframe['Email'] = merged_df.sort_values(by='Email')['Email']\n",
        "    dataframe['Manager? (Y/N)'] = merged_df.sort_values(by='Email')['Manager? (Y/N)']\n",
        "    dataframe['Courses'] = merged_df.sort_values(by='Email')['Course Name']\n",
        "    dataframe['Role/Title'] = merged_df.sort_values(by='Email')['Job']\n",
        "    dataframe['Geo / Location'] = merged_df.sort_values(by='Email')['Location']\n",
        "    dataframe['Reports To:'] = merged_df.sort_values(by='Email')['Supervisor_Name']\n",
        "    dataframe['Sub Department / Team'] = merged_df.sort_values(by='Email')['Sub_Department']\n",
        "    dataframe['Department'] = merged_df.sort_values(by='Email')['Department']\n",
        "    dataframe['Status'] = merged_df.sort_values(by='Email')['Status']\n",
        "    dataframe['Percentage Complete']= merged_df.sort_values(by='Email')['Percentage Complete']\n",
        "    dataframe['Time Spent (ONLY COMPLETED)']= merged_df.sort_values(by='Email')['Days Taken']\n",
        "    dataframe = merged_df.fillna('')\n",
        "    dataframe['Email'] = dataframe['Email'].astype(str) + dataframe['Email'].ne(dataframe['Email'].shift()).replace({True: ' ', False: ''})\n",
        "  worksheet.update([dataframe.columns.values.tolist()] + dataframe.values.tolist())\n",
        "\n",
        "def split_dataframe_by_unique_values(df, column_name):\n",
        "  unique_values = df[column_name].unique()\n",
        "  dataframes = []\n",
        "  for value in unique_values:\n",
        "      subset_df = df[df[column_name] == value].copy()\n",
        "      dataframes.append(subset_df)\n",
        "  return dataframes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below loads the LearnUpon Data from the excel (found under the Employee Data sheet)"
      ],
      "metadata": {
        "id": "lu5NhYT482aC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTAr3-u2O9ww"
      },
      "outputs": [],
      "source": [
        "EmployeeData_Df=WorksheetLoading('Employee Data')\n",
        "EmployeeData_Df['Name'] = EmployeeData_Df.apply(lambda row: str(row['Last Name']) +', ' + row['First Name'], axis=1)\n",
        "EmployeeData_Df['Full_Name']=EmployeeData_Df['Name'].str.title()\n",
        "EmployeeData_Df\n",
        "clear_output()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below calculates the days taken, whether a person is a manager, and whether a course is completed. **NOTE:** it takes around 5 minutes to load."
      ],
      "metadata": {
        "id": "R1x7bhQM9Miq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atrlZPEMTyCi"
      },
      "outputs": [],
      "source": [
        "frequency_df=EmployeeData_Df[['email','First Name', 'Last Name', 'Status','Percentage Complete','Course name']]\n",
        "frequency_df.columns = ['Email', 'First Name','Last Name', 'Status','Percentage Complete','Course Name']\n",
        "frequency_df = frequency_df.assign(Employee_Name=frequency_df['First Name'].astype(str) +' '+ frequency_df['Last Name'])\n",
        "frequency_df=frequency_df.drop('First Name', axis=1)\n",
        "frequency_df=frequency_df.drop('Last Name', axis=1)\n",
        "for email in frequency_df['Email']:\n",
        "    count = 'Not Completed'\n",
        "    for idx, row in EmployeeData_Df.iterrows():\n",
        "      if 'Managers at Contentstack' in row['Groups'] and email == row['email']:\n",
        "        frequency_df.at[idx, 'Manager? (Y/N)'] = 'Y'\n",
        "frequency_df['Manager? (Y/N)'] = frequency_df['Manager? (Y/N)'].fillna('N')\n",
        "frequency_df=frequency_df.reset_index()\n",
        "frequency_df.replace({np.nan: 'Not Completed'}, inplace = True)\n",
        "frequency_df.replace({'': '0 '}, inplace = True)\n",
        "frequency_df.replace({'Not Completed': ' '}, inplace = True)\n",
        "frequency_df=frequency_df.rename(columns={\"Days Taken\": \"Days_Taken\",\n",
        "                                          \"Manager? (Y/N)\": \"Manager?\"})\n",
        "frequency_df['Percentage Complete'] = frequency_df['Percentage Complete'].replace('-', '0%')\n",
        "frequency_df\n",
        "clear_output()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below reads the People Ops Data that I got from UKG (another dataset)"
      ],
      "metadata": {
        "id": "GCAweaKP94ne"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCsY3Get6SpK"
      },
      "outputs": [],
      "source": [
        "PeopleOps_Df=WorksheetLoading('People Ops Data')\n",
        "PeopleOps_Df=PeopleOps_Df.rename(columns={\"Employee Email\": \"email\",\n",
        "                                          \"Employee Name (Last Suffix, First MI)\": \"Full_Name\",\n",
        "                                          \"Supervisor Name (First MI Last Suffix)\": \"Supervisor_Name\",\n",
        "                                          \"Org Level 1\": \"Department\",\n",
        "                                          \"Org Level 2\": \"Sub_Department\"})\n",
        "\n",
        "PeopleOps_Df.head(30)\n",
        "clear_output()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this below to install SQL"
      ],
      "metadata": {
        "id": "JDwfbntgGc6o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0_MVef1J9Yy",
        "outputId": "d91fccf6-2da8-4c4c-e320-a75519dc134a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SQLAlchemy==2.0.18\n",
            "  Downloading SQLAlchemy-2.0.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m2.0/2.7 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy==2.0.18) (4.7.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy==2.0.18) (2.0.2)\n",
            "Installing collected packages: SQLAlchemy\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.20\n",
            "    Uninstalling SQLAlchemy-2.0.20:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.20\n",
            "Successfully installed SQLAlchemy-2.0.18\n"
          ]
        }
      ],
      "source": [
        "pip install SQLAlchemy==2.0.18\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below uses SQL to join the data together"
      ],
      "metadata": {
        "id": "-VPqtTrhGgAC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHf0G7eRzI8E"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine\n",
        "\n",
        "engine = create_engine('sqlite://',\n",
        "                       echo = False)\n",
        "\n",
        "EmployeeData_Df.to_sql('AllEmployeeData',\n",
        "               con = engine)\n",
        "PeopleOps_Df.to_sql('PeopleOpsData',\n",
        "               con = engine)\n",
        "\n",
        "with engine.connect() as conn:\n",
        "  Connect_df = conn.exec_driver_sql(\"SELECT PeopleOpsData.email, PeopleOpsData.Full_Name, PeopleOpsData.Job, PeopleOpsData.Supervisor_Name, PeopleOpsData.Department, PeopleOpsData.Sub_Department, PeopleOpsData.Location FROM PeopleOpsData LEFT JOIN AllEmployeeData ON AllEmployeeData.email = PeopleOpsData.email\").fetchall()\n",
        "Connect_df=pd.DataFrame(Connect_df)\n",
        "Connect_df=Connect_df.rename(columns={\"email\": \"Email\"})\n",
        "Connect_df\n",
        "clear_output()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below uses Python to join additional data together."
      ],
      "metadata": {
        "id": "RYlcE1TbGjM_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydRchF-ShBm2"
      },
      "outputs": [],
      "source": [
        "merged_df = pd.merge(frequency_df, Connect_df, on='Email', how='inner')\n",
        "merged_df=merged_df.drop_duplicates()\n",
        "merged_df=merged_df.reset_index()\n",
        "merged_df=merged_df.drop('index',axis=1)\n",
        "merged_df=merged_df.sort_values('Course Name')\n",
        "merged_df=merged_df.reset_index()\n",
        "merged_df=merged_df.drop('index',axis=1)\n",
        "merged_df=merged_df.drop('level_0', axis=1)\n",
        "\n",
        "merged_df\n",
        "clear_output()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRRKcXrOax24"
      },
      "outputs": [],
      "source": [
        "update_values = merged_df.sort_values(by='Course Name').values.tolist()\n",
        "CourseWorksheet = sh.worksheet(\"Course A\")\n",
        "CourseWorksheet.update([merged_df.columns.values.tolist()] + update_values)\n",
        "clear_output()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}