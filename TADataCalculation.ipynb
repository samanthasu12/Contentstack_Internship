{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samanthasu12/Contentstack_Internship/blob/main/TADataCalculation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Welcome to my TA Automation Project!**\n",
        "----\n",
        "\n",
        "Here are the steps in which you need to take to automate the data.\n",
        "\n",
        "1. Make sure that all the sheets are completely blank except for the column titles.\n",
        "\n",
        "2. Insert the Hired AND Viable Candidates report into the Hired AND Viable Candidates sheet. **NOTE:** The report must contain the following columns: First Name,\tLast Name,\tURM,\tDepartment,\tJob Name,\tStart Date (Application),\tStatus,\tOffices,\tRequisition ID,\tRecruiter (the order doesn't matter though).\n",
        "\n",
        "3. Make sure the sheet names in the google sheet are the following: Sheet1, Hired and Viable Candidates Table, India Only, India Only Table, US/EMEA/ROW Only, US/EMEA/ROW Only Table, and Hired AND Viable Candidates. (Do not change the names of the sheets or any of the column titles!)\n",
        "\n",
        "4. After you've completed your checks, please click Runtime (located at the very top of the colab) and Run All. It will then ask you to connect the google colab to your own google account, and you just need to sign in.\n",
        "\n",
        "5. Please give it around 5 seconds to fully automate. (Might be longer depending on how big the report is)"
      ],
      "metadata": {
        "id": "D4IZuOGj39HZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from google.auth import default\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from google.colab import drive\n",
        "from google.colab import auth\n",
        "from IPython.display import clear_output\n",
        "from google.colab import files\n",
        "\n",
        "creds, _ = default()\n",
        "drive.mount('/content/drive/')\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "drive.mount(\"mnt\")\n",
        "\n",
        "sheet_id='1qZh3oDeFjUqQu8RecKGn-Wb9BE3m0iI3OYab1dBg52I'\n",
        "#the sheet_id is the \"key\" to unlocking the spreadsheet that I am importing/exporting onto/from (which in this case is the TA Master Spreadsheet).\n",
        "#The key is found after /d/ and before /edit in https://docs.google.com/spreadsheets/d/1qZh3oDeFjUqQu8RecKGn-Wb9BE3m0iI3OYab1dBg52I/edit#gid=317505658\n",
        "\n",
        "sh = gc.open_by_key(sheet_id)\n",
        "sh.worksheets()\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "phZeG7i6-cl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Hired_And_Viable_Candidates_Worksheet=sh.worksheet('Hired AND Viable Candidates') #This is the Sheet Name\n",
        "Hired_And_Viable_Candidates_Worksheet=Hired_And_Viable_Candidates_Worksheet.get_all_values()\n",
        "headers1 = Hired_And_Viable_Candidates_Worksheet.pop(0)\n",
        "allcandidatesdata=pd.DataFrame(Hired_And_Viable_Candidates_Worksheet, columns=headers1)"
      ],
      "metadata": {
        "id": "Hs4wW22-mnGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below reorganizes the data in the format we want it. This organized dataset is stored under the variable frequency_df."
      ],
      "metadata": {
        "id": "kp_bCgrgFkrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#I am taking the data from the previous dataset that we just created in the previous cell and automating it here, onto a new dataset.\n",
        "frequency_df=allcandidatesdata[['Requisition ID', 'Offices','Department','Job Name']].value_counts().reset_index()\n",
        "frequency_df.columns = ['Requisition ID', 'Offices','Department', 'Job Name', 'Viable Candidates']\n",
        "\n",
        "countlist=[]\n",
        "count2list=[]\n",
        "count3list=[]\n",
        "count4list=[]\n",
        "count5list=[]\n",
        "count6list=[]\n",
        "extracountlist=[]\n",
        "extracountlist2=[]\n",
        "\n",
        "#this chunk of code here is the automation machine; it gets all the numbers in the right places.\n",
        "for job in frequency_df['Requisition ID']:\n",
        "  count=0\n",
        "  count2=0\n",
        "  count3=0\n",
        "  count4='N'\n",
        "  count5=0\n",
        "  count6=0\n",
        "  extracount=0\n",
        "  extracount2='N'\n",
        "  for idx, row in allcandidatesdata.iterrows():\n",
        "    if 'Female' in row['URM'] and job in row['Requisition ID']:\n",
        "      count+=1\n",
        "    if (job in row['Requisition ID']) and (('Asian / Pacific Islander' in row['URM']) or ('Middle Eastern' in row['URM']) or ('Hispanic / Latinx' in row['URM']) or ('Native Hawaiian / Other Pacific Islander' in row['URM']) or ('African American / Black' in row['URM'])):\n",
        "      count2+=1\n",
        "    if (job in row['Requisition ID']) and ('Female' in row['URM']) and (('Asian / Pacific Islander' in row['URM']) or ('Middle Eastern' in row['URM']) or ('Hispanic / Latinx' in row['URM']) or ('Native Hawaiian / Other Pacific Islander' in row['URM']) or ('African American / Black' in row['URM'])):\n",
        "      count3+=1\n",
        "      if 'Hired' in row['Status']:\n",
        "        count4='Y'\n",
        "        count5+=1\n",
        "    if job in row['Requisition ID'] and 'Hired' in row['Status']:\n",
        "      count6+=1\n",
        "    if (job in row['Requisition ID']) and ('Female' in row['URM']) and 'Hired' in row['Status']:\n",
        "      extracount+=1\n",
        "      extracount2='Y'\n",
        "  countlist.append(count)\n",
        "  count2list.append(count2)\n",
        "  count3list.append(count3)\n",
        "  count4list.append(count4)\n",
        "  count5list.append(count5)\n",
        "  count6list.append(count6)\n",
        "  extracountlist.append(extracount)\n",
        "  extracountlist2.append(extracount2)\n",
        "frequency_df['Female Presented']=countlist\n",
        "frequency_df['URM Presented']=count2list\n",
        "frequency_df['Total F-URM per job']=count3list\n",
        "frequency_df['F-URM Hired?']=count4list\n",
        "frequency_df['Number of F-URM Hired']=count5list\n",
        "frequency_df['Total Hired']=count6list\n",
        "frequency_df['Number of Female Hired']=extracountlist\n",
        "frequency_df['Female Hired?']=extracountlist2\n",
        "\n",
        "#this chunk of code over here removes all of the interns\n",
        "for idx, row in frequency_df.iterrows():\n",
        "  if 'Intern' in row['Job Name']:\n",
        "    frequency_df.drop([idx], axis=0, inplace=True)\n",
        "\n",
        "#this sorts it alphabetically, firstly by 'Department' and secondly by 'Job Name'\n",
        "frequency_df=frequency_df.sort_values(by=['Department', 'Job Name'])\n",
        "frequency_df=frequency_df.reset_index()\n",
        "frequency_df=frequency_df.drop('index', axis=1)\n",
        "\n",
        "#this places the subgroups into their respective main groups\n",
        "def map_department(value):\n",
        "    if 'Business Operations' in value or 'People Team' in value or 'General and Administrative' in value or 'Legal' in value or 'Finance' in value:\n",
        "      return 'G&A'\n",
        "    if 'Business Development' in value or 'Marketing' in value or 'Product Marketing' in value or 'Revenue Marketing' in value or 'Corporate Communications' in value or 'Digital Experience' in value or 'Operations' in value:\n",
        "      return 'Marketing'\n",
        "    if 'TSO' in value or 'Sale Engineering' in value or 'Customer Success' in value or 'Partnerships' in value or 'Growth' in value or 'Partnerships' in value or 'Sales General' in value:\n",
        "      return 'Sales'\n",
        "    if 'Customer Support' in value or 'Engineering' in value or 'Product Development' in value or 'Product Management' in value or 'Admin' in value or 'Cloud SRE' in value or 'Cloud - COGS' in value or 'Cloud - R&D' in value or 'Design' in value or 'DevOps' in value:\n",
        "      return 'Product Dev.'\n",
        "    else:\n",
        "        return value\n",
        "\n",
        "frequency_df['Department'] = frequency_df['Department'].map(map_department)"
      ],
      "metadata": {
        "id": "17P2x7gCycxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the code below to update the data onto sheet1."
      ],
      "metadata": {
        "id": "hLzVfSHRIKGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the 'Sheet1' worksheet with the updated values from 'frequency_df'\n",
        "update_values = frequency_df.sort_values(by='Department').values.tolist()\n",
        "Sheet1_Worksheet = sh.worksheet(\"Sheet1\")\n",
        "Sheet1_Worksheet.update([frequency_df.columns.values.tolist()] + update_values)\n",
        "\n",
        "# Clear output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "ECdVACcdugyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perfect! We've uploaded our first sheet! Let's keep going.\n"
      ],
      "metadata": {
        "id": "ei0fVupYIfWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now let's automate the table for the previous dataset we just created onto a separate spreadsheet!**\n",
        "\n",
        "Note: The chart will automate on its own once we import this data.\n",
        "\n",
        "The code below finds specific values for each **department**."
      ],
      "metadata": {
        "id": "CMo0Rqye2Zvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "departmental_values = frequency_df['Department'].unique()\n",
        "departmental_values=pd.DataFrame(departmental_values, columns=['Department'])\n",
        "\n",
        "count7list=[]\n",
        "count8list=[]\n",
        "count9list=[]\n",
        "count10list=[]\n",
        "count11list=[]\n",
        "count12list=[]\n",
        "for value in departmental_values['Department']:\n",
        "  count7=0\n",
        "  count8=0\n",
        "  count9=0\n",
        "  count10=0\n",
        "  count11=0\n",
        "  count12=0\n",
        "  for idx, row in frequency_df.iterrows():\n",
        "    if value in row['Department']:\n",
        "        count7+= row['Viable Candidates']\n",
        "        count8+= row['Female Presented']\n",
        "        count9+= row['URM Presented']\n",
        "        count10+= row['Total F-URM per job']\n",
        "        count11+= row['Number of F-URM Hired']\n",
        "  count7list.append(count7)\n",
        "  count8list.append(count8)\n",
        "  count9list.append(count9)\n",
        "  count10list.append(count10)\n",
        "  count11list.append(count11)\n",
        "departmental_values['Viable Candidates']=count7list\n",
        "departmental_values['Total Female Presented']=count8list\n",
        "departmental_values['Total URM Presented']=count9list\n",
        "departmental_values['Total F-URM Presented']=count10list\n",
        "departmental_values['Total F-URM Hired']=count11list\n",
        "departmental_values['Proportion of F-URM Candidates Provided']=[round(a / b,2) if b != 0 else 0.0 for a, b in zip(count10list, count7list)]\n",
        "departmental_values['Proportion of F-URM Candidates Hired']=[round(a / b,2) if b != 0 else 0.0 for a, b in zip(count11list, count8list)]\n",
        "\n",
        "departmental_values=departmental_values.sort_values(by=['Department'])\n",
        "departmental_values=departmental_values.reset_index()\n",
        "departmental_values=departmental_values.drop('index', axis=1)"
      ],
      "metadata": {
        "id": "IpkVNOIyDqWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "update_values = departmental_values.sort_values(by='Department').values.tolist()\n",
        "Sheet1Table_Worksheet = sh.worksheet(\"Hired and Viable Candidates Table\")\n",
        "Sheet1Table_Worksheet.update([departmental_values.columns.values.tolist()] + update_values)\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "gbn7PDYxtGlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 4**: Creating a Dataset That Only Includes India-based candidates\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "Lk-e-jW83P45"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This creates the dataset for only India-based candidates."
      ],
      "metadata": {
        "id": "SLZDNN5G5s0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#this part includes only the rows that include the word India\n",
        "filtered_dfIndia= pd.DataFrame()\n",
        "for index, row in frequency_df.iterrows():\n",
        "    if 'India'  in row['Offices']:\n",
        "        filtered_dfIndia = filtered_dfIndia.append(row)\n",
        "filtered_dfIndia=filtered_dfIndia.reset_index()\n",
        "clear_output()\n",
        "\n",
        "#this part gets rid of URM and F-URM columns\n",
        "filtered_dfIndia=filtered_dfIndia.drop('URM Presented', axis=1)\n",
        "filtered_dfIndia=filtered_dfIndia.drop('Total F-URM per job', axis=1)\n",
        "filtered_dfIndia=filtered_dfIndia.drop('Number of F-URM Hired', axis=1)\n",
        "filtered_dfIndia=filtered_dfIndia.drop('F-URM Hired?', axis=1)\n",
        "filtered_dfIndia=filtered_dfIndia.drop('index', axis=1)\n"
      ],
      "metadata": {
        "id": "kVh26Lb_4EyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below updates the data"
      ],
      "metadata": {
        "id": "ZhqivsUuZ8kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "update_values = filtered_dfIndia.sort_values(by='Department').values.tolist()\n",
        "IndiaWorksheet = sh.worksheet(\"India Only\")\n",
        "IndiaWorksheet.update([filtered_dfIndia.columns.values.tolist()] + update_values)"
      ],
      "metadata": {
        "id": "2yg93gUL5MO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f36709a-623f-4f04-e267-0732bda0801b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1qZh3oDeFjUqQu8RecKGn-Wb9BE3m0iI3OYab1dBg52I',\n",
              " 'updatedRange': \"'India Only'!A1:I32\",\n",
              " 'updatedRows': 32,\n",
              " 'updatedColumns': 9,\n",
              " 'updatedCells': 288}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_dfIndia_Table = filtered_dfIndia['Department'].unique()\n",
        "filtered_dfIndia_Table=pd.DataFrame(filtered_dfIndia_Table, columns=['Department'])\n",
        "\n",
        "count7list=[]\n",
        "count8list=[]\n",
        "count9list=[]\n",
        "for value in filtered_dfIndia_Table['Department']:\n",
        "  count7=0\n",
        "  count8=0\n",
        "  count9=0\n",
        "  for idx, row in filtered_dfIndia.iterrows():\n",
        "    if value in row['Department']:\n",
        "        count7+= row['Viable Candidates']\n",
        "        count8+= row['Female Presented']\n",
        "        count9+= row['Number of Female Hired']\n",
        "  count7list.append(count7)\n",
        "  count8list.append(count8)\n",
        "  count9list.append(count9)\n",
        "filtered_dfIndia_Table['Viable Candidates']=count7list\n",
        "filtered_dfIndia_Table['Total Female Presented']=count8list\n",
        "filtered_dfIndia_Table['Total Female Hired']=count9list\n",
        "filtered_dfIndia_Table['Proportion of Female Candidates Provided']=[round(a / b,2) if b != 0 else 0.0 for a, b in zip(count8list, count7list)]\n",
        "filtered_dfIndia_Table['Proportion of Female Candidates Hired']=[round(a / b,2) if b != 0 else 0.0 for a, b in zip(count9list, count8list)]\n",
        "filtered_dfIndia_Table['Proportion of Proportion of F-URM Candidates Provided']=[round(a / b,2) if b != 0 else 0.0 for a, b in zip(count9list, count8list)]"
      ],
      "metadata": {
        "id": "wyiI9WNNkVDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below selects the sheet that I want to import onto"
      ],
      "metadata": {
        "id": "W6l4tHJ1aKET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "update_values = filtered_dfIndia_Table.sort_values(by='Department').values.tolist()\n",
        "IndiaTableWorksheet = sh.worksheet(\"India Only Table\")\n",
        "IndiaTableWorksheet.update([filtered_dfIndia_Table.columns.values.tolist()] + update_values)\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "tPsqM5-z5XCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below updates the sheet"
      ],
      "metadata": {
        "id": "A24yz26caQNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 4**: Creating a Dataset That Only Includes US/EMEA/ROW-Based Candidates\n",
        "\n",
        "---\n",
        "\n",
        "(EXLUDES INDIA!)"
      ],
      "metadata": {
        "id": "0vGpMeYhM5vQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_dfnotIndia = pd.DataFrame()\n",
        "for index, row in frequency_df.iterrows():\n",
        "    if 'India' not in row['Offices']:\n",
        "        filtered_dfnotIndia = filtered_dfnotIndia.append(row)\n",
        "filtered_dfnotIndia=filtered_dfnotIndia.reset_index()\n",
        "clear_output()\n",
        "filtered_dfnotIndia=filtered_dfnotIndia.drop('index', axis=1)"
      ],
      "metadata": {
        "id": "4J_q-IKv3hCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "update_values = filtered_dfnotIndia.sort_values(by='Department').values.tolist()\n",
        "NotIndiaWorksheet = sh.worksheet(\"US/EMEA/ROW Only\")\n",
        "NotIndiaWorksheet.update([filtered_dfnotIndia.columns.values.tolist()] + update_values)"
      ],
      "metadata": {
        "id": "inq-cuSz6sx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ddc8e18-ad65-419e-accc-a825646c9302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1qZh3oDeFjUqQu8RecKGn-Wb9BE3m0iI3OYab1dBg52I',\n",
              " 'updatedRange': \"'US/EMEA/ROW Only'!A1:M20\",\n",
              " 'updatedRows': 20,\n",
              " 'updatedColumns': 13,\n",
              " 'updatedCells': 260}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_values = filtered_dfnotIndia['Department'].unique()\n",
        "unique_df=pd.DataFrame(unique_values, columns=['Department'])\n",
        "\n",
        "count7list=[]\n",
        "count8list=[]\n",
        "count9list=[]\n",
        "count10list=[]\n",
        "count11list=[]\n",
        "count12list=[]\n",
        "for value in unique_df['Department']:\n",
        "  count7=0\n",
        "  count8=0\n",
        "  count9=0\n",
        "  count10=0\n",
        "  count11=0\n",
        "  count12=0\n",
        "  for idx, row in filtered_dfnotIndia.iterrows():\n",
        "    if value in row['Department']:\n",
        "        count7+= row['Viable Candidates']\n",
        "        count8+= row['Female Presented']\n",
        "        count9+= row['URM Presented']\n",
        "        count10+= row['Total F-URM per job']\n",
        "        count11+= row['Number of F-URM Hired']\n",
        "  count7list.append(count7)\n",
        "  count8list.append(count8)\n",
        "  count9list.append(count9)\n",
        "  count10list.append(count10)\n",
        "  count11list.append(count11)\n",
        "unique_df['Viable Candidates']=count7list\n",
        "unique_df['Total Female Presented']=count8list\n",
        "unique_df['Total URM Presented']=count9list\n",
        "unique_df['Total F-URM Presented']=count10list\n",
        "unique_df['Number of F-URM Hired']=count11list\n",
        "unique_df['Proportion of F-URM Candidates Provided']=[round(a / b,2) if b != 0 else 0.0 for a, b in zip(count10list, count7list)]\n",
        "unique_df['Proportion of F-URM Candidates Hired']=[round(a / b,2) if b != 0 else 0.0 for a, b in zip(count11list, count8list)]"
      ],
      "metadata": {
        "id": "Y5KmZu8-MWes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "update_values = unique_df.sort_values(by='Department').values.tolist()\n",
        "NotIndiaTableWorksheet = sh.worksheet(\"US/EMEA/ROW Only Table\")\n",
        "NotIndiaTableWorksheet.update([unique_df.columns.values.tolist()] + update_values)"
      ],
      "metadata": {
        "id": "DY7HZLgDCO9l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b480782b-25f5-4a8d-c08d-b434a0877d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1qZh3oDeFjUqQu8RecKGn-Wb9BE3m0iI3OYab1dBg52I',\n",
              " 'updatedRange': \"'US/EMEA/ROW Only Table'!A1:H5\",\n",
              " 'updatedRows': 5,\n",
              " 'updatedColumns': 8,\n",
              " 'updatedCells': 40}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}